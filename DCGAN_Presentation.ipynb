{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Presentation and Workshop\n",
    "#### By Ovik and Ben\n",
    "![Nebula](https://camo.githubusercontent.com/a83b960f54a8fe5d134904665a489df701f0fb8b31a856155d377fecc9071e83/68747470733a2f2f63646e2e646973636f72646170702e636f6d2f6174746163686d656e74732f3930343536333938393736303036353534312f3932373234353631313134333637313831382f746573745f362e6a7067)  \n",
    "\n",
    "GANs are cool; let's make something cool with them. The GAN in this code generates images of nebulas, but it can really be used to make any kind of image. \n",
    "\n",
    "### Sources:\n",
    "- https://github.com/Ovikx/Nebula-GAN-TF\n",
    "- https://github.com/Ovikx/PyTorch-GAN\n",
    "- https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- https://github.com/soumith/ganhacks\n",
    "\n",
    "### Further Reading:\n",
    "- https://arxiv.org/abs/1701.00160\n",
    "- https://arxiv.org/abs/1606.03498\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "First, let's install everything we need. Here are the instructions for the required packages via pip:\n",
    "| Package | Directions |\n",
    "| ------- | ---------- |\n",
    "| `torch` | Use the install menu on the PyTorch [homepage](https://pytorch.org/) and paste the output into terminal|\n",
    "| `numpy` | Type `pip install numpy` into terminal |\n",
    "| `matplotlib` | Type `pip install matplotlib` into terminal |\n",
    "| `ckpt_manager` | Type `pip install pytorch-ckpt-manager` into terminal |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ckpt_manager import CheckpointManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the constants\n",
    "We'll need to define some constants for data preparation and the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation constants\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "# Training constants/hyperparameters\n",
    "IMG_SAVE_INTERVAL = 10\n",
    "MODEL_SAVE_INTERVAL = 10\n",
    "EPOCHS = 2000\n",
    "GEN_LR = 2e-4\n",
    "DISC_LR = 2e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up GPU so we can get a decent image within the next decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA (for NVIDIA GPUs) if available\n",
    "device = torch.device(type='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')\n",
    "\n",
    "# Pray to NVIDIA that this line actually helps performance\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Data Preparation\n",
    "\n",
    "One of the most important parts of this program!\n",
    "We have to resize all of the images and convert them to Tensors so that we can feed it to the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=IMAGE_SIZE),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# Create the image dataset\n",
    "train_loader = DataLoader(\n",
    "    dataset=datasets.ImageFolder('images', transform=transform),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for item in train_loader:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[tensor([[[[0.0510, 0.0471, 0.0431,  ..., 0.0549, 0.0471, 0.0471],\n",
    "          [0.0784, 0.0431, 0.0392,  ..., 0.0392, 0.0392, 0.0471],\n",
    "          [0.0510, 0.0471, 0.0510,  ..., 0.0392, 0.0392, 0.0510],\n",
    "          ...,\n",
    "          [0.0275, 0.0314, 0.0588,  ..., 0.0235, 0.0275, 0.0235],\n",
    "          [0.0275, 0.0235, 0.0235,  ..., 0.0275, 0.0314, 0.0235],\n",
    "          [0.0392, 0.0275, 0.0314,  ..., 0.0314, 0.0353, 0.0314]],\n",
    "\n",
    "         [[0.0314, 0.0196, 0.0196,  ..., 0.0275, 0.0196, 0.0235],\n",
    "          [0.0588, 0.0157, 0.0157,  ..., 0.0118, 0.0118, 0.0196],\n",
    "          [0.0157, 0.0275, 0.0275,  ..., 0.0118, 0.0157, 0.0275],\n",
    "          ...,\n",
    "          [0.0196, 0.0275, 0.0510,  ..., 0.0196, 0.0235, 0.0196],\n",
    "          [0.0235, 0.0196, 0.0196,  ..., 0.0235, 0.0275, 0.0196],\n",
    "          [0.0353, 0.0235, 0.0314,  ..., 0.0275, 0.0314, 0.0275]],\n",
    "\n",
    "         [[0.1490, 0.1490, 0.1529,  ..., 0.1490, 0.1451, 0.1451],\n",
    "          [0.1686, 0.1451, 0.1451,  ..., 0.1412, 0.1373, 0.1412],\n",
    "          [0.1451, 0.1529, 0.1529,  ..., 0.1451, 0.1412, 0.1529],\n",
    "          ...,\n",
    "          [0.0627, 0.0706, 0.0902,  ..., 0.0824, 0.0863, 0.0824],\n",
    "          [0.0706, 0.0588, 0.0627,  ..., 0.0824, 0.0824, 0.0824],\n",
    "          [0.0824, 0.0745, 0.0784,  ..., 0.0863, 0.0902, 0.0902]]],\n",
    "          [0.0118, 0.0118, 0.0157,  ..., 0.0039, 0.0039, 0.0039],\n",
    "          ...,\n",
    "          [0.7569, 0.7529, 0.7451,  ..., 0.8627, 0.8627, 0.8627],\n",
    "          [0.7569, 0.7529, 0.7451,  ..., 0.8745, 0.8745, 0.8745],\n",
    "          [0.7608, 0.7529, 0.7451,  ..., 0.8824, 0.8824, 0.8824]]]]), tensor([0, 0, 0, 0])]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Defining the Generator\n",
    "\n",
    "Time to define the Generator. It takes an array of random float values as input and returns a 256 x 256 x 3 Tensor (RGB pixel values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Takes in a 1D tensor (essentially a 1D array in this context) of random numbers and outputs an image represented by a 3D tensor\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Defines the layer structure.\n",
    "        Conv2dTranspose layers expand the image\n",
    "        '''\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_stack = nn.Sequential(\n",
    "            # Creates a massive 1D tensor for the following layers to reshape into a 3D tensor\n",
    "            nn.Linear(\n",
    "                in_features=100,\n",
    "                out_features=8*8*2048,\n",
    "                bias=False\n",
    "            ),\n",
    "\n",
    "            # Batch normalization helps according to https://arxiv.org/pdf/1701.00160.pdf\n",
    "            nn.BatchNorm1d(8*8*2048),\n",
    "            nn.LeakyReLU(0.3),\n",
    "\n",
    "            # Turns that 1D tensor into a 3D tensor\n",
    "            # The target shape is (3, 256, 256) for a 256x256 RGB image\n",
    "            # We will progressively transform the 3D tensor into the target shape using convolution 2D transpose layers\n",
    "            nn.Unflatten(\n",
    "                dim=1,\n",
    "                unflattened_size=(2048,8,8)\n",
    "            )\n",
    "\n",
    "            # Output size: 2048, 8, 8\n",
    "        )\n",
    "\n",
    "        self.conv_stack1 = nn.Sequential(\n",
    "            # Creates more pixels from a single pixel\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=2048,\n",
    "                out_channels=1024,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                padding_mode='zeros',\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.3)\n",
    "\n",
    "            # Output size: 1024, 8, 8\n",
    "        )\n",
    "\n",
    "        self.conv_stack2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=1024,\n",
    "                out_channels=512,\n",
    "                kernel_size=4,\n",
    "                padding=1,\n",
    "                stride=2,\n",
    "                padding_mode='zeros',\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.3)\n",
    "\n",
    "            # Output size: 512, 16, 16\n",
    "        )\n",
    "\n",
    "        self.conv_stack3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=512,\n",
    "                out_channels=256,\n",
    "                kernel_size=4,\n",
    "                padding=1,\n",
    "                stride=2,\n",
    "                padding_mode='zeros',\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.3)\n",
    "\n",
    "            # Output size: 256, 32, 32\n",
    "        )\n",
    "\n",
    "        self.conv_stack4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=4,\n",
    "                padding=1,\n",
    "                stride=2,\n",
    "                padding_mode='zeros',\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.3)\n",
    "\n",
    "            # Output size: 128, 64, 64\n",
    "        )\n",
    "\n",
    "        self.conv_stack5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                padding=1,\n",
    "                stride=2,\n",
    "                padding_mode='zeros',\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.3)\n",
    "\n",
    "            # Output size: 64, 128, 128\n",
    "        )\n",
    "\n",
    "        self.conv_stack6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=3,\n",
    "                kernel_size=4,\n",
    "                padding=1,\n",
    "                stride=2,\n",
    "                padding_mode='zeros',\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "            # Size: 3, 256, 256\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Passes the input through the layer structure (aka forward propagation)\n",
    "        '''\n",
    "        x = self.dense_stack(x)\n",
    "        x = self.conv_stack1(x)\n",
    "        x = self.conv_stack2(x)\n",
    "        x = self.conv_stack3(x)\n",
    "        x = self.conv_stack4(x)\n",
    "        x = self.conv_stack5(x)\n",
    "        x = self.conv_stack6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Discriminator\n",
    "\n",
    "Now let's define the Discriminator. It takes a 256 x 256 x 3 Tensor as input and returns a number within `(-inf, inf)`. \n",
    "\n",
    "Since the Discriminator is supposed to decide if an image is real or fake, we will map the output to `(0, 1)`. `1` means the Discriminator predicted the image is real and `0` means fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Predicts whether or not the input image is real. The discriminator's output range is (-inf, inf),\n",
    "    but the loss function will map the output to (0, 1). 0 means fake and 1 means real.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Defines the layer structure. Pretty standard convolutional network\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_stack1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding_mode='zeros'\n",
    "            ),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.conv_stack2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding_mode='zeros'\n",
    "            ),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.conv_stack3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=256,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding_mode='zeros'\n",
    "            ),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.dense1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=256*31*31,\n",
    "                out_features=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack1(x)\n",
    "        x = self.conv_stack2(x)\n",
    "        x = self.conv_stack3(x)\n",
    "        x = self.dense1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Creating the models\n",
    "Now that we have defined the Generator and Discriminator classes, we can create the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator and discriminator objects\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the loss function\n",
    "Since our models deal with 2 possible predictions (real or fake), we can use the binary cross-entropy loss function.\n",
    "\n",
    "We will use the logits version since we need to squeeze the Discriminator's output range between 0 and 1. The [loss function's documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) says this is more \"numerically stable\" than just using a Sigmoid activation function for the last layer in the Discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function we are going to use for both the generator and the discriminator\n",
    "loss_function = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the optimizers\n",
    "For this GAN we'll use the ADAM optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models' respective optimizers\n",
    "generator_opt = torch.optim.Adam(generator.parameters(), lr=GEN_LR)\n",
    "discriminator_opt = torch.optim.Adam(discriminator.parameters(), lr=DISC_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Checkpoint Manager (OPTIONAL)\n",
    "Losing training progress for GANs is incredibly annoying, so we're going to use a utility to handle saving and loading models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint manager that will help save/load models automatically (docs: https://pypi.org/project/pytorch-ckpt-manager/)\n",
    "manager = CheckpointManager(\n",
    "    assets={\n",
    "        'gen' : generator.state_dict(),\n",
    "        'disc' : discriminator.state_dict(),\n",
    "        'gen_opt' : generator_opt.state_dict(),\n",
    "        'disc_opt' : discriminator_opt.state_dict()\n",
    "    },\n",
    "    directory='training_ckpts',\n",
    "    file_name='nebula_states',\n",
    "    maximum=3\n",
    ")\n",
    "\n",
    "# Load the states from the checkpoint directory if they exist\n",
    "load_data = manager.load()\n",
    "generator.load_state_dict(load_data['gen'])\n",
    "discriminator.load_state_dict(load_data['disc'])\n",
    "generator_opt.load_state_dict(load_data['gen_opt'])\n",
    "discriminator_opt.load_state_dict(load_data['disc_opt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Miscellaneous stuff we need to define before training\n",
    "\n",
    "We'd like to see how our model is doing in terms of image quality, so we'll create a function that we'll use to print sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bunch of tensors populated by random floats\n",
    "# This is the input for the generator to create sample images that will be saved\n",
    "seed = torch.randn((16, 100), device=device)\n",
    "\n",
    "def save_predictions(epoch, z):\n",
    "    '''\n",
    "    Saves a sample of generated images\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        predictions = (generator(z).cpu().detach().numpy()*255).astype('int32')\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    for i, image in enumerate(predictions):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(np.moveaxis(image, 0, -1), cmap=None)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.savefig(f'generated_images/gen_{epoch}')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Training!\n",
    "\n",
    "Here's a basic outline of the training process:\n",
    "1. Train the Discriminator on real images\n",
    "1. Train the Discriminator on fake images \n",
    "1. Use the Discriminator's prediction for the fake images to train the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    '''\n",
    "    Trains the generator and discriminator\n",
    "    '''\n",
    "\n",
    "    loader_size = len(train_loader)\n",
    "    print('Starting training...')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Start recording stats for display\n",
    "        start = time.time()\n",
    "        running_g_loss = torch.tensor([0], dtype=torch.float16, device=device)\n",
    "        running_d_loss = torch.tensor([0], dtype=torch.float16, device=device)\n",
    "        \n",
    "        # Train each batch in the dataset\n",
    "        for data in train_loader:\n",
    "            # Get the real images and their respective labels\n",
    "            images, labels = data[0].to(device), torch.ones((BATCH_SIZE,1), device=device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            for param in generator.parameters():\n",
    "                param.grad = None\n",
    "            for param in discriminator.parameters():\n",
    "                param.grad = None\n",
    "\n",
    "            # Get the generator's images\n",
    "            noise = torch.randn((BATCH_SIZE, 100), device=device)\n",
    "            fake_images = generator(noise)\n",
    "\n",
    "            # Backprop for the discriminator's guesses on the real images\n",
    "            # Goal for the discriminator is to correctly guess that the real images are real\n",
    "            # In theory, the loss function will compare the discriminator's predictions to 1.0 because 1.0 means real\n",
    "            # We are using 0.9 because discriminator over-confidence can harm the generator's training\n",
    "            real_guess = discriminator(images)\n",
    "            disc_real_loss = loss_function(real_guess, torch.full_like(labels, 0.9, device=device))\n",
    "            running_d_loss += disc_real_loss.to(torch.float16)\n",
    "            disc_real_loss.backward()\n",
    "\n",
    "            # Backprop for the discriminator's guesses on the fake images\n",
    "            # 2nd goal for the discriminator is to correctly guess that the fake images are fake\n",
    "            # The loss function will compare the discriminator's predictions to 0.0 because 0.0 means fake\n",
    "            fake_guess = discriminator(fake_images.detach())\n",
    "            disc_fake_loss = loss_function(fake_guess, torch.zeros_like(fake_guess, device=device))\n",
    "            running_d_loss += disc_fake_loss.to(torch.float16)\n",
    "            disc_fake_loss.backward()\n",
    "            \n",
    "            # Generator loss\n",
    "            # Goal for the generator is to fool the discriminator into thinking that its generated images are real\n",
    "            # The loss function will compare the discriminator's predictions to 1.0 because the generator wants the discriminator to think its images are real\n",
    "            fake_guess = discriminator(fake_images)\n",
    "            gen_loss = loss_function(fake_guess, torch.ones_like(fake_guess, device=device))\n",
    "            running_g_loss += gen_loss.to(torch.float16)\n",
    "            gen_loss.backward()\n",
    "\n",
    "            # Update the weights for both models\n",
    "            generator_opt.step()\n",
    "            discriminator_opt.step()\n",
    "            \n",
    "        # Save sample images\n",
    "        if (epoch + 1) % SAVE_INTERVAL == 0:\n",
    "            save_predictions(epoch+1, seed)\n",
    "        \n",
    "        # Save the model and optimizer states to a folder\n",
    "        if (epoch + 1) % MODEL_SAVE_INTERVAL == 0:\n",
    "            manager.save()\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Print the stats for the current epoch\n",
    "        print(f'Epoch {epoch+1} || Gen loss: {(running_g_loss/loader_size).item()} || Disc loss: {(running_d_loss/loader_size).item()} || {end-start} seconds')\n",
    "\n",
    "# Sets your computer on fire\n",
    "train(EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56757521627d17a1ede13a5b0f5a7c166bd42e3f8b7acc3114282f83b6a05016"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
